%%%%%%%%%%%%%%%%%%%% Preamble %%%%%%%%%%%%%%%%%%%%
\documentclass[10pt, paper=a4]{article}
\usepackage{amssymb,amsfonts,amsmath,latexsym,amsthm, mathtools} %mathtext,
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{chngpage}
\usepackage{cprotect}
\usepackage[font=footnotesize, labelsep=period]{caption}
\usepackage{cite}
\usepackage[scale=0.925]{geometry}
\graphicspath{{images/}}
\usepackage[pdftex,unicode,colorlinks, citecolor=blue,
  filecolor=black, linkcolor=blue, urlcolor=blue]{hyperref}
\usepackage[figure,table]{hypcap}
%%%%%%%%%%%%%%%%%%%% Document %%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%% Title page %%%%%%%%%%%%%%%%%%%%
\title{Report 02 --- Regression and classification of age of abalones}

\author{Dmitriy Markovich and Julian Lemos Vinasco}

\date{}

\maketitle

\begin{abstract}
  We solve the regression problem of predicting the age of abalones on
  the basis of its measured physical characteristics, as well as the
  similar classification problem of predicting the age of range of
  abalones.  We consider linear regression (LR), linear regression
  with forward selection (FLR), decision trees (DT), k nearest
  neighbors (KNN), naive bayes (NB), artificial neural networks (ANN),
  and multinomial regression (MNMR) methods.  For regression problem,
  we found that the ANN model performs best, and the FLR and AVE
  models are indistinguishable from each other.  For classification
  problem, we found the ANN and MNMR to be the best performing models,
  and showed them to perform better than the largest class (Lcl)
  classifier and the linear regression models (LR) using the paired
  t-test.
  %% Objective: The objective of this second report is to apply the
  %% methods you have learned in the second section of the course on
  %% ”Supervised learning: Classification and regression” in order to
  %% solve both a relevant classification and regression problem for your
  %% data.
\end{abstract}

%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%
\section{Regression}
\label{sec:regression}

\subsection{Problem description}
The linear regression objective is to predict the Abalon's age based
on 9 given attributes.  The attributes considered for Linear
Regression (LR) are presented next: Sex, Length, Diameter, Height,
Whole weight (WhlWght), Shucked weight (ShckdWght), Viscera weight
(VscrWght) and Shell weight (ShllWght).  More details about the data
set can be found in \cite{datadescription}.

\subsection{Linear Regression with forward selection}
Prior to the LR, the relation between the dependent variable Age and
the independent attributes was explored by a generalized additive
model~\cite{gam}.  Fig.~\ref{fig:gam} shows that the attributes
Length, WhlWght and ShckdWght do not have a linear relation with Age.
The graphs suggest that exponential terms of this attributes are
needed.

\begin{figure}[h]
  \centering
  \includegraphics[width = 0.75\textwidth]{gam.pdf}
  \caption{Relation of attributes Length, Diameter, Height, WhlWght,
    ShckdWght, and ShllWght with Age explored with the generalized
    additive model.  Length, WhlWght and ShckdWght do not have a
    linear relation with Age.}
  \label{fig:gam}
\end{figure}

Additionally, an initial LR model was implemented in order to check
the model's assumptions.  Fig.~\ref{fig:modelcheck}a clearly shows a
trumpet shape that suggests the need for a logarithmic transformation
of the response variable Age.  Additionally, it is clear from the
Cook's distance that observation 2052 is an outlier and therefore is
removed from the data.

\begin{figure}[h]
  \begin{minipage}{0.3\textwidth}
    a)\\
    \includegraphics[width = 0.99\textwidth]{modelcheck.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.3\textwidth}
    b)\\
    \includegraphics[width = 0.99\textwidth]{forwardselection.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.3\textwidth}
    c)\\
    \includegraphics[width = 0.99\textwidth]{finalmodelcheck.pdf}
  \end{minipage} \vfill
  \begin{minipage}{0.99\textwidth}
    d)\\
    \begin{center}
      \scriptsize
      \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c}
      \toprule
      Attribute & Intercept & SexI & SexM & Length & $Length^2$ & Diameter & Height &
      WhlWght & $WhlWght^2$ & ShckdWght & $ShckdWght^2$ & ShllWght \\
      \midrule
      Coefficient & 0.252 & -0.027 & 0.002 & 1.781 & -1.8 & 0.271 & 0.358 &
      0.444 & -0.097 & -1.138 & 0.568 & 0.338\\
      \bottomrule
    \end{tabular}
    \end{center}
  \end{minipage}
  \caption{a) Initial LR model fitted to the data.  The trumpet shape
    of residuals suggests a logarithmic transformation for the
    variable Age.  The plot of Cook's distance shows that observation
    2052 is an outlier.  b) Linear regression method with forward
    selection fitted to data. The plot of squared error as the
    function of iteration shows that the best model is the one at
    iteration 10. The selected attributes at iteration 10 define the
    model formula as described by Eq.~\ref{eq:model_formula}.  c)
    Model check of Eq.~\ref{eq:model_formula} fitted to the data.
    Normal Q-Q plot shows the deviation from normality.  d) The
    coefficients of model in Eq.~\ref{eq:model_formula} fitted to
    data.}
  \label{fig:modelcheck}
\end{figure}

The forward selection (FLR) with 10-fold cross-validation to perform
sequential feature selection was implemented considering previous
analysis.  Fig.~\ref{fig:modelcheck}b shows the squared error and the
attributes selected in each iteration.  The model obtained at
iteration 10 has the lowest error and is therefore the best model
produced by the method.

\subsection{Model Interpretation}
The formula of the best model in Fig.~\ref{fig:modelcheck}b reads:
\begin{equation}
  \log{(Age)} = Sex + Length + Length^2 + Diameter + Height + WhlWght + WhlWght^2 + ShckdWght + ShckdWght^2 + ShllWght
  \label{eq:model_formula}
\end{equation}

The coefficients of the model can be found in
Fig.~\ref{fig:modelcheck}c.  The Age base line is described by the
intercept.  Then, the positive coefficients in the attributes SexM,
Length, Diameter, Height, WhlWght, ShckdWght$^2$ and ShllWght
indicated that the Age is expected to be higher if the values of this
attributes increase.  On the other hand, the negative coefficients for
SexI, Length$^2$, WhlWght$^2$ indicated a reduction in the expected
Age.  Notice that the negative coefficients of the squared attributes
represent a correction in the linear attributes.  This is due to the
fact that Age is in a nonlinear relation with these terms.

Eq.~\ref{eq:model_formula} model check is presented in
Fig.~\ref{fig:modelcheck}c.  A pattern in the residuals can be clearly
seen on the residuals plot, and the Normal Q-Q plot shows a deviation
from normality.

%% \newpage
%% \begin{table}[ht]
%% \centering
%% \begin{tabular}{rrrrrrrrrrrrr}
%%   \hline
%%  & (Intercept) & SexI & SexM & Length & $Length^2$ & Diameter \\ 
%%  \hline
%%  Coefficients & 0.252 & -0.027 & 0.002 & 1.781 & -1.800 & 0.271 \\
%%  \hline
%%  & Height & WhlWght & $WhlWght^2$ & ShckdWght & $ShckdWght^2$ & ShllWght \\ 
%%   \hline
%%  Coefficients & 0.358 & 0.444 & -0.097 & -1.138 & 0.568 & 0.338 \\ 
%%    \hline
%% \end{tabular}
%% \caption{Model coefficients}
%% \label{tab:modelcoefficients}
%% \end{table}

%% \begin{figure}[h]
%%   \centering
%%   \includegraphics[width = 0.49\textwidth]{finalmodelcheck.pdf}
%%   \caption{Final model assumptions check.}
%%   \label{fig:finalmodelcheck}
%% \end{figure}

\subsection{Artificial Neural Network}
An Artificial Neural Network (ANN) model to solve the regression
problem is the following.  Age is a continuous variable, a function of
all other attributes.  The ANN was implemented using $k=3$
cross-validation folds and 1 hidden unit.  Fig.~\ref{fig:ann_lr}a
shows the best of the three ANN fitted.  The residual error for each
of the cross-validation splits is shown in Fig.~\ref{fig:ann_lr}b.

%% The ANN was fitted to considering a logarithmic transformation of the
%% response variable.  This was due to this transformation was made in
%% the previous section and was important to have the same scale in both
%% models in order to make a proper comparison.

%% \newpage
\begin{figure}[h]
  \centering
  \begin{minipage}{0.3\textwidth}
    a)\\
    \includegraphics[width = 0.99\textwidth]{ANN_LR.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.3\textwidth}
    b)\\
    \includegraphics[width = 0.99\textwidth]{ANN_LR_Error.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.3\textwidth}
    c)\\
    \includegraphics[width = 0.99\textwidth]{Regression_comparison1.pdf}
  \end{minipage} \vfill
  \caption{a) Visualization of the ANN with one hidden unit fitted to
    the data.  b) Residual error for each of the cross-validation
    folds.  c) {\color{red} NEED FIXES FOR THE PLOT!} Performance
    comparison of FLR, ANN, and average age (AVE) model.}
  \label{fig:ann_lr}
\end{figure}


\subsection{Models Comparison}
The comparison of the models was made using 3-fold cross-validation
for the ANN and the LR with forward selection models along with the
error for the average of the training data output.
Fig.~\ref{fig:ann_lr}c shows the results of the comparison using the
paired t-test.  From the the plot it is clearly seen that the best
method was the ANN having a lower error in each of the
cross-validation folds.  Notice that the comparison of the models was
made only with 3-folds due to the fact that ANN was too computational
demanding, making the job extremely time-consuming for a bigger number
of folds.

%% \begin{figure}[h]
%% \centering
%% \includegraphics[width = 0.49\textwidth]{Regression_comparison1.pdf}
%% \caption{Error rate comparison between ANN, Average and LR with forward selection}
%% \label{fig:lr_comparison}
%% \end{figure}

%% \clearpage
%%%%%%%%%%%%%%%%%%%% Classification %%%%%%%%%%%%%%%%%%%%
\section{Classification}
\label{sec:classification}

%% \begin{enumerate}
%% \item Explain which classification problem you have chosen to solve.
%% \item Apply at least three of the following methods: Decision Trees
%%   (as in Fig.~\ref{fig:decision_tree}), Logistic/Multinomial
%%   Regression (as in Lst.~\ref{lst:logistic_regression}), K-Nearest
%%   Neighbors (KNN), Naı̈ve Bayes and Artificial Neural Networks (ANN).
%%   (Use cross-validation to select relevant parameters in an inner
%%   cross-validation loop and give in a table the performance results
%%   for the methods evaluated on the same cross-validation splits on the
%%   outer cross-validation loop, i.e. you should use two levels of
%%   cross-validation).
%% \item For the models you are able to interpret explain how a new data
%%   observation is classified.  (If you have multiple models fitted,
%%   (i.e., one for each cross-validation split) either focus on one of
%%   these fitted models or consider fitting one model for the optimal
%%   setting of the parameters estimated by cross-validation to all the
%%   data.)
%% \item Statistically compare the performance of the two best performing
%%   models (i.e., use a paired t-test). Compare in addition if the
%%   performance of your models are better than simply predicting all
%%   outputs to be the largest class in the training data.
%% \end{enumerate}

%% There are two important aspects of classification and regression
%% methods, how well the methods can predict unlabeled data and how well
%% the method describe what aspects in the data causes the data to be
%% classified a certain way.

\subsection{Clasification problem for the dataset}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The classification problem for the dataset is to predict the age range
of abalones using their measured physical characteristics.  Age in
years as an attribute can be calculated from the Rings attribute as
Age = 1.5 + Rings.  The original distribution of the Age attribute and
is presented in Fig.~\ref{fig:age_grouping}a.

\begin{figure}[htbp]
  \centering \includegraphics[width =
    0.99\textwidth]{age_grouping.pdf} \cprotect\caption{a) Original
    distribution of the Age attribute derived from Rings attribute as
    Age = 1.5 + Rings.  b) Equal length splitting of the original Age
    attribute using \verb|R cut| function.  c) Quantile groups
    splitting of the original Age attribute using \verb|R cut2|
    function.}
  \label{fig:age_grouping}
\end{figure}

To formulate a classification problem, the continuous Age attribute
has to be splitted into several groups.  There are different ways to
perform this grouping --- either dividing the Age interval into pieces
of equal length as shown in Fig.~\ref{fig:age_grouping}b using the
standard \verb|cut| function in \verb|R|, or dividing the interval
into quantile groups as shown in Fig.~\ref{fig:age_grouping}b using
the function \verb|cut2|.  The advantage of the equal length splitting
is that it mostly retains the original distribution of the Age
attribute, whereas the quantile groups splitting results in a lot more
uniform distribution.  From the perspective of the classification
problem, when a dominant class is present in the dataset with a huge
number of counts compared to other classes, even a ``null'' largest
class classifier will have a decent error rate.  However we are not
supposed to solve class imbalance problems in this particular report,
so we will proceed with predicting the Age range using the equal
length splitting, and then compare the obtained results to the ones
for quantile groups splitting.

\subsection{Applying different methods to solve classification problem}
\subsubsection{Decision trees} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Decision tree (DT) is a tool that uses a tree-like model of decisions
and their possible consequences.  The goal of applying a decision tree
to the data is to find out how, on the basis of all other attributes,
to classify the age according to splitting in
Fig.~\ref{fig:age_grouping}b.

The complexity of the decision tree model is defined by its complexity
parameter $cp$.  Generally, a full decision tree with $cp = 0$ results
in overfitting --- it has a very low error rate on the training
dataset, but a very large error on the test dataset.  Adjusting the
value of complexity parameter with one layer K-fold cross-validation
is performed in the following way: the data is splitted K times into
non-overlapping test and train datasets, and the number of
observations in the test dataset is N / K, where N is the total number
of observations.  The full decision tree with $cp = 0$ is fitted to
the train data, and then the obtained tree is pruned using a certain
vector of complexity parameters.  At each of the pruning levels, the
pruned tree is used to predict the classes of the test dataset, and
the classification error is calculated.  Averaging over K splits of
data, the plot of the generalization error as a function of the
complexity parameter allows to find the best model suggested by K-fold
cross-validation.  The result of applying one-layer 10-fold
cross-validation for decision tree model selection to the data is
presented in Fig.~\ref{fig:decision_trees}a.  Minimum number of
observations in the node to attempt splitting was set to 5.  The
estimated optimal value of the complexity parameter is 0.00263 and the
error rate is 22.6 \%.  As Fig.~\ref{fig:decision_trees}a shows,
adjusting the complexity parameter brings the training and the test
errors virtually to the same scale, which is clearly not the case when
$cp = 0$.

\begin{figure}[h!]
  \centering
  \begin{minipage}{0.49\textwidth}
    a)\\
    \includegraphics[width = 0.9\textwidth]{decision_tree_err_CV1.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.49\textwidth}
    b)\\
    \includegraphics[width = 0.9\textwidth]{decision_tree_CV2.pdf}
  \end{minipage} \vfill
  \begin{minipage}{0.99\textwidth}
    c)\\
    \begin{center}
      \includegraphics[width = 0.58\textwidth]{decision_tree.pdf}
    \end{center}
  \end{minipage} \vfill
  \cprotect\caption{a) One-layer 10-fold cross-validation for decision
    tree model selection.  Minimum number of observations in the node
    to attempt splitting was set to 5.  The optimal pruning level is
    0.00263 and the error rate is 22.6 \%.  b) Two-layer 10 by 10
    cross-validation for decision tree model selection.
    \verb|cp.best| is the complexity parameter value of the best model
    selected in the inner cross-validation loop.  The cross-validated
    generalization error of the decision tree algorithm is $\simeq$
    23.1 \%.  c) Decision tree model with \verb|cp = 0.005| fitted to
    the whole dataset.}
  \label{fig:decision_trees}
\end{figure}

In practice, the one-layer cross-validation for optimal model
selection is combined with the basic cross-validation for estimation
of the generalization error, and that results in the two-layer
cross-validation, that both selects the optimal model and estimates
its generalization error.  The result of applying two-layer 10 by 10
cross-validation for decision tree model selection to the data is
presented in Fig.~\ref{fig:decision_trees}b.  For each of the
cross-validation splits on the outer loop, the error rate of the best
model and the parameter value \verb|cp.best| characterizing the best
model are presented.  So, the error rate or rather the cross-validated
generalization error of the decision tree algorithm is $\simeq$ 23.1
\%.  This result is compared to the performance of other
classification methods in Fig.~\ref{fig:performance}e.

After performing two-layer cross-validation, it is instructive to
interpret the decision tree model by fitting it to the whole dataset.
We chose \verb|cp = 0.005|, and the obtained model is visualized in
Fig.~\ref{fig:decision_trees}c.  The visualization suggests that the
most important decisions are made on the basis of just two attributes
--- \verb|ShllWght| and \verb|ShkcdWght|.  For several relatively
small leaf nodes containing the \verb|(13.7, 19.3]| Age range,
attributes \verb|Height| and \verb|Diameter| are also important.
Taking a new observation, asking the questions suggested by the
decision tree and following the decision instructions defined by the
answers, one can classify it as shown in
Fig.~\ref{fig:decision_trees}c.

\subsubsection{K nearest neighbours}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
K nearest neighbors (KNN) algorithm is used in pattern recognition for
classification problem.  A nearest neighbor classifier computes the
distance to all data objects, finds the nearest k data objects, and
classifies according to the majority of votes.  The results of
applying two-layer 10 by 10 cross-validation for the k nearest
neighbors model selection is presented in Fig.~\ref{fig:performance}a.
For each of the cross-validation splits on the outer loop, the error
rate of the best model and the parameter value \verb|kNN.best| (the
number of nearest neighbors) characterizing the best model are
presented.  The cross-validated generalization error of the k nearest
neighbors algorithm is $\simeq$ 22.9 \%.  This result is compared to
the performance of other classification methods in
Fig.~\ref{fig:performance}e.

\subsubsection{Naive Bayes}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Naive Bayes (NB) classifiers are a family of simple probabilistic
classifiers based on applying Bayes' theorem with strong (naive)
independence assumptions between the features.  The results of
applying two-layer 10 by 10 cross-validation for the naive Bayes
algorithm is presented in Fig.~\ref{fig:performance}b.  On all the
splits, the default model was used with the provided \verb|naiveBayes|
function and standard model parameters \verb|distribution = "normal"|
and \verb|prior = "empirical"|.  The cross-validated generalization
error of the naive Bayes algorithm is $\simeq$ 45.7 \%.  This result
is compared to the performance of other classification methods in
Fig.~\ref{fig:performance}e.

\subsubsection{Artificial Neural Network}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Artificial neural networks (ANN) are a family of models inspired by
biological neural networks and are used to estimate or approximate
functions that can depend on a large number of inputs and are
generally unknown.  Artificial neural networks are generally presented
as systems of interconnected ``neurons'' which exchange messages
between each other.  The connections have numeric weights that can be
tuned based on experience, making neural nets adaptive to inputs and
capable of learning.  As with the multinomial regression, the
artificial neural network can be extended for multi-class
classification problem using the softmax function.  The results of
applying two-layer 10 by 10 cross-validation for the artificial neural
network model selection is presented in Fig.~\ref{fig:performance}c.
For each of the cross-validation splits on the outer loop, the error
rate of the best model and the parameter value
\verb|HHiddenUnits.best| (the number of hidden units in the single
hidden layer of the network) characterizing the best model are
presented.  The cross-validated generalization error of the artificial
neural network model is $\simeq$ 21.1 \%.  We limited ourselves to
maximum 5 hidden units in the model. This result is compared to the
performance of other classification methods in
Fig.~\ref{fig:performance}e.  The model containing 4 hidden units, as
suggested by Fig.~\ref{fig:performance}c, fitted to the whole data is
visualized in Fig.~\ref{fig:ANN}.

\begin{figure}[h!]
  \centering
  \begin{minipage}{0.45\textwidth}
    \includegraphics[width = 0.99\textwidth]{ANN.png}
  \end{minipage} \vfill
  \caption{The visualization of the artificial neural network model
    containing 4 hidden units, fitted to the whole data.}
  \label{fig:ANN}
\end{figure}

\subsubsection{Multinomial regression}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The basic linear regression model can be extended using the binomial
cost function and the logit link function to the logistic regression
model.  The logistic regression model can be used for classification,
but it is capable do distinguish only between two classes.  The
extension of the logistic regression by using the softmax function
results in the ability to distinguish between more than two classes,
and the model is then called the multinomial regression model (MNMR).
The results of applying two-layer 10 by 10 cross-validation for the
multinomial regression model is presented in
Fig.~\ref{fig:performance}d.  No parameters of the model were tuned in
the inner cross-validation loop (tuning was not discussed in the
lectures or excercises).  The cross-validated generalization error of
the multinomial regression model is $\simeq$ 21.6 \%.  This result is
compared to the performance of other classification methods in
Fig.~\ref{fig:performance}e.

\subsubsection{Performance comparison of the considered methods}
Fig.~\ref{fig:performance}e shows the comparison of cross-validation
generalization errors of the considered classification methods.  ANN
and MNMR show the best results, and NB --- the worst.  If exactly the
same analysis as described above is performed using the alternative
quantile groups splitting as shown in Fig.~\ref{fig:age_grouping}c,
then the performance table for the methods looks like in
Fig.~\ref{fig:performance}d.  Again, ANN and MNMR show the best
results, and NB is the worst, but the error rate of all methods except
NB becomes effectively twice as large.

\begin{figure}[h!]
  \begin{minipage}{0.49\textwidth}
    a)\\
    \includegraphics[width = 0.9\textwidth]{k_nearest_neighbors_CV2.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.49\textwidth}
    b)\\
    \includegraphics[width = 0.9\textwidth]{naive_bayes_CV1.pdf}
  \end{minipage} \vfill
  \begin{minipage}{0.49\textwidth}
    c)\\
    \includegraphics[width = 0.9\textwidth]{artificial_neural_network_CV2.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.49\textwidth}
    d)\\
    \includegraphics[width = 0.9\textwidth]{multinomial_regression_CV1.pdf}
  \end{minipage} \vfill
  \begin{minipage}{0.49\textwidth}
    e) Equal length splitting using \verb|cut|\\
    \begin{center}
    \begin{tabular}{c|c|c|c|c|c}
      \toprule
      Method & DT & KNN & NB & ANN & MNMR\\
      \midrule
      Error rate, \% & 23.1 & 22.9 & {\color{red} 45.7} & {\color{green} 21.1} & {\color{green} 21.6}\\
      \bottomrule
    \end{tabular}
    \end{center}
  \end{minipage} \hfill
  \begin{minipage}{0.49\textwidth}
    f) Group quantiles splitting using \verb|cut2|\\
    \begin{center}
      \begin{tabular}{c|c|c|c|c|c}
        \toprule
        Method & DT & KNN & NB & ANN & MNMR\\
        \midrule
        Error rate, \% & 47.5 & 49.2 & {\color{red} 54.4} & {\color{green} 45.8} & {\color{green} 46.4}\\
        \bottomrule
      \end{tabular}
    \end{center}
  \end{minipage} \hfill
  \cprotect\caption{a) Two-layer 10 by 10 cross-validation for the k
    nearest neighbors (KNN) model selection.  \verb|kNN.best| is the
    number of neighbors parameter value of the best model selected in
    the inner cross-validation loop.  b) Two-layer 10 by 10
    cross-validation for the naive Bayes (NB) algorithm.  On all the
    splits, the default model was used with the provided
    \verb|naiveBayes| function and standard model parameters
    \verb|distribution = "normal"| and \verb|prior = "empirical"|.  c)
    Two-layer 10 by 10 cross-validation for the artificial neural
    network (ANN) model selection.  \verb|NHiddenUnits.best| is the
    number of hidden units parameter value of the best model selected
    in the inner cross-validation loop.  d) Two-layer 10 by 10
    cross-validation for the multinomial regression model (MNMR). No
    parameters of the model were tuned in the inner cross-validation
    loop (tuning was not discussed in the lectures or excercises). e)
    Comparison of cross-validated generalization errors of the
    considered classification methods for equal length splitting as in
    Fig.~\ref{fig:age_grouping}b.  ANN and MNMR show the best results,
    NB is the worst.  f) Same as e) but for quantile groups splitting
    as in Fig.~\ref{fig:age_grouping}c.  Again, ANN and MNMR show the
    best results, and NB is the worst.}
  \label{fig:performance}
\end{figure}

\subsection{Statistical comparison of two best performing models}
As indicated by both Fig.~\ref{fig:performance}e-f, the two best
performing models are ANN and MNMR models.  We can statistically
compare their performance between each other, as well as with the
``null'' largest class classifier (LCl).  Statistical comparison of
two models is performed in the following way.  The populations of the
error rates of the classifiers are compared using a paired t-test, and
if the difference in their means is significantly non-zero, then one
classifier is better than the other.  The outer layer of the
cross-validation is used to get a sample of generalization errors of
the two models.  Next, if the means of the populations of the error
rates are significantly different, the test-statistic will produce a
very low p-value (p-value $\leq$ 0.05) of the paired t-test, which
under the null hypothesis indicates the probability that the
classifiers are not significantly different.  The populations of the
error rates of Lcl, ANN, and MNMR models are presented in
Fig.~\ref{fig:comparison}.  In parenthesis after ANN and MNMR, the
p-value of the paired t-test comparing the classifier with Lcl is
presented.  The p-value of the t-test comparing ANN with MNMR is
presented separately.

\begin{figure}[h!]
  \begin{minipage}{0.49\textwidth}
    a) Equal length splitting using \verb|cut|\\
    \includegraphics[width = 0.9\textwidth]{classifier_comparison_cut_1.pdf}
  \end{minipage} \hfill
  \begin{minipage}{0.49\textwidth}
    b) Group quantiles splitting using \verb|cut2|\\
    \includegraphics[width = 0.9\textwidth]{classifier_comparison_cut_2.pdf}
  \end{minipage} \vfill
  \caption{The populations of the error rates of Lcl, ANN, and MNMR
    models are presented in Fig.~\ref{fig:comparison}.  In parenthesis
    after ANN and MNMR, the p-value of the paired t-test comparing the
    classifier with Lcl is presented.  The p-value of the t-test
    comparing ANN with MNMR is presented separately. a) Equal length
    splitting of the Age attribute.  b) Group quantiles splitting of
    the Age attribute.}
  \label{fig:comparison}
\end{figure}

Despite the $\simeq$ 2-fold difference in absolute values, for both
Fig.~\ref{fig:comparison}a-b, ANN and MNMR classifiers are
significantly different from the LCl, because corresponding the
p-values of the paired t-tests are extremely low.  At the same time,
we must conclude that for both cases ANN and MNMR are not
significantly different from each other, though the difference is more
obvious in Fig.~\ref{fig:comparison}b than in
Fig.~\ref{fig:comparison}a.

%%%%%%%%%%%%%%%%%%%% Results and Discussion %%%%%%%%%%%%%%%%%%%%
\section{Results and Discussion}
\label{sec:results_and_discussion}

Model checks of the considered FLR and ANN models show that the
assumption of the normality of the residuals are not fully fullfilled.
Therefore, a logarithmic transformation of the dependent variable was
employed.  This approach is not recommended because of the
difficulties in comparison of re-scaled and original models.
Furthermore, model's coefficients interpretation should be treated
with care because of the same fact.  Nevertheless, the performance
comparison of the models shows that the ANN model performs best, and
the FLR and AVE models are indistinguishable from each other.

The considered classification problem for the dataset was to predict
the age range of abalones using their measured physical
characteristics.  We have investigated two possible strategies of
splitting the continuous attribute Age into groups --- using equal
length splitting, or quantile groups splitting.  In both cases, the
lowest cross-validated generalization errors were obtained for
artificial neural network (ANN) model and multinomial regression
(MNMR) model, though the classification error rates for the equal
length splitting were 2-fold lower than the error rates for group
quantile splitting.  Statistical comparison of ANN and MNMR using the
paired t-test showed that the classifiers are not significantly
different from each other, but significantly different from the
``null'' largect class classifier.


%% If your data has previously been analyzed by regression or
%% classification in the lit- erature, please report what methods have
%% been used previously as well as their performance and relate your
%% results to these previous results.

%% Notice, if the analysis of your data is too computationally demanding
%% for choosing parameters in the inner cross-validation loop we suggest
%% you use the hold-out method instead of K-fold
%% cross-validation. Furthermore, if analyzing the data by ANN is too
%% computationally demanding you can consider only analyzing a subset of
%% your data by ANN.

%% The report should be 5-10 pages long including figures and tables and
%% give a precise and coherent account of the results of the regression
%% and classification methods applied to your data. Please hand in the
%% report by uploading it as a single, uncompressed .pdf file to
%% CampusNet no later than {\bf 12 April at 13:00}.  To ensure all group
%% members get credit for the report, put your names and study numbers on
%% the front page and ensure you upload the report as a group hand in and
%% put the name of your dataset on the front page.
%%%%%%%%%%%%%%%%%%%% Bibliography %%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{10}
\bibitem{datadescription} \url{http://archive.ics.uci.edu/ml/datasets/Abalone}
\bibitem{gam} \url{https://en.wikipedia.org/wiki/Generalized_additive_model}
\bibitem{Waugh.thesis} S.~Waugh,''Extending and Benchmark
  Cascade-Correlation,'' Thesis, 1997.
\bibitem{Mayukh} H.~Mayukh, ``Age of Abalones using Physical
  Characteristics: A Classification Problem,'' ECE 539 Fall 2010
  Project Report, Department of Electrical and Computer Engineering
  University of Wisconsin-Madison, 2010.
\end{thebibliography}
\end{document}
